{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Numba, Scipy, Trackpy, ipyparallel & pims before you run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Sun Mar 29 15:40:11 2020 @author: Talha\n",
    "Most of this code comes from \"walkthrough\" tutorial on Tracky website: http://soft-matter.github.io/trackpy/v0.4.2/tutorial/walkthrough.html\n",
    "and ideas on stepsize implementation from Han Yang's code\n",
    "\"\"\"\n",
    "#Use Jupyter notebooks to make use of your multi-core processors; before importing trackpy to allow multi-core processing use the magic command: %%px\n",
    "#Don't forget to turn on the \"IPython Clusters\" in Jupyter to enjoy better speeds using parallel computing\n",
    "\n",
    "from __future__ import division, unicode_literals, print_function  # for compatibility with Python 2 and 3\n",
    "#%env PYTHONHASHSEED=0#important command to get reproducible results of D from cut traj using trackpy 5.0, but slows down code\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pims\n",
    "import csv\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from itertools import chain\n",
    "\n",
    "# change the following to %matplotlib notebook for interactive plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# tweak styles.\n",
    "mpl.rc('figure',  figsize=(10, 6))\n",
    "mpl.rc('image', cmap='red')\n",
    "\n",
    "from ipyparallel import Client\n",
    "client = Client()\n",
    "view = client.load_balanced_view()\n",
    "import trackpy as tp\n",
    "tp.quiet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import trackpy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save your movie as tiff using Imagej before opening it here!\n",
    "path = 'trackpy_testing/0p8_2k_trackpy2'\n",
    "name = '0p8_2k_trackpy2'\n",
    "frames = pims.TiffStack(path + '.tif', as_grey=True)#opens the tiffstack of movie frames\n",
    "frames#gives you info about pixels and frames\n",
    "\n",
    "# make a preview figure of a frame's particles detected\n",
    "f = tp.locate(frames[0], 7, minmass=80) #adjust minmass if all the molecules are not correctly located\n",
    "plt.figure()  \n",
    "tp.annotate(f, frames[0]);\n",
    "'''\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(f['mass'], bins=20)\n",
    "ax.set(xlabel='mass', ylabel='count');\n",
    "#shows bias\n",
    "plt.figure()\n",
    "tp.subpx_bias(tp.locate(frames[:], 9, minmass=1000));\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_preload = list(frames[:])#load all frames\n",
    "\n",
    "# tp.batch, which calls tp.locate on each frame and collects the results\n",
    "#f = tp.batch(frames_preload[:1998], 7, minmass=29000, max_iterations=1, characterize=False, processes=\"auto\");\n",
    "f = tp.batch(frames_preload[:1998], 7, minmass=10, characterize=False, processes=\"auto\");#radius is always an odd number\n",
    "\n",
    "#implementats Crocker-Grier linking algorithmto link trajectories, needs to specify a maximum displacement between adjacent frames\n",
    "#Memory keeps track of disappeared particles and maintains their ID for up to some number of frames after their last appearance\n",
    "t = tp.link_df(f, 10, memory=5)\n",
    "plt.figure()\n",
    "tp.plot_traj(t, label=True, superimpose=None);\n",
    "\n",
    "# Compare the number of particles in the unfiltered and filtered data \n",
    "# that last for a given number of frames.\n",
    "t1 = tp.filter_stubs(t, (len(frames_preload)-5))\n",
    "print('Before:', t['particle'].nunique(),'After:', t1['particle'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to play with the impact of displavement and memory to further improve tracking\n",
    "t = tp.link_df(f, 5, memory=35)\n",
    "plt.figure()\n",
    "tp.plot_traj(t, label=True, superimpose=None);\n",
    "\n",
    "# Compare the number of particles in the unfiltered and filtered data \n",
    "# that last for a given number of frames.\n",
    "t1 = tp.filter_stubs(t, 900)\n",
    "tp.plot_traj(t1, label=True, superimpose=None);\n",
    "print('Before:', t['particle'].nunique(),'After:', t1['particle'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Compute xy drift and remove drift\n",
    "drft = tp.compute_drift(t1)\n",
    "tm = tp.subtract_drift(t1.copy(), drft)\n",
    "plt.figure()\n",
    "ax = tp.plot_traj(tm)\n",
    "\n",
    "#If you would like to use HD5 format:\n",
    "\n",
    "#PandasHDFStore -- fastest for a small (~100) number of frames\n",
    "#PandasHDFStoreBig -- fastest for a medium or large number of frames\n",
    "#PandasHDFStoreSingleNode -- optimizes HDF queries that access multiple frames (advanced)\n",
    "with tp.PandasHDFStoreSingleNode('data.h5') as s:\n",
    "    tp.batch(frames_preload[:1998], 7, minmass=60, characterize=False, processes=\"auto\", output=s)\n",
    "    all_results = s.dump()    \n",
    "with tp.PandasHDFStore('data.h5') as s:\n",
    "    # As before, we require a minimum \"life\" of 5 frames and a memory of 4 frames\n",
    "    for linked in tp.link_df_iter(s, 2, memory=2):\n",
    "        s.put(linked)\n",
    "    # get results by frame with s.get(frame_number) or, when you have sufficient memory, retrieve them all\n",
    "    trajectories = pd.concat(iter(s))\n",
    "trajectories.head()\n",
    "'''\n",
    "'''\n",
    "#adaptive search; refer to tutorial on Adaptive Search on trackpy website\n",
    "tracks_adaptive = tp.link_df(f, 0.95, adaptive_stop=0.56, adaptive_step=0.99)\n",
    "tracks_adaptive.groupby('particle').particle.count().value_counts()\n",
    "plt.figure()\n",
    "ax = tp.plot_traj(tracks_adaptive)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stepsize Calculation by frame:\n",
    "i=0\n",
    "j=1\n",
    "stepsize_list = []\n",
    "for i in range(len(frames_preload)-2):\n",
    "    mtn = tp.motion.relate_frames(t1, i, j)#Find the displacement vector of all particles between two frames\n",
    "    step = np.sqrt((mtn.dx**2) + (mtn.dy**2))*254\n",
    "    #print(mtn)\n",
    "    #print(step)\n",
    "    i = i+1\n",
    "    j = j+1\n",
    "    stepsize_list.append(step[:].tolist())\n",
    "steps = list(chain.from_iterable(stepsize_list))#make the combined list of stepsizes from all the frames\n",
    "med_step = np.nanmedian(steps)##calculates the median step size\n",
    "print(r'The median stepsize is {0:.3f} nm'.format(med_step))\n",
    "\n",
    "#saves step sizes in a text file\n",
    "with open(('step' + name + '.txt'), 'w') as f:\n",
    "    for s in steps:\n",
    "        f.write(\"%s\\n\" % s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the mean squared displacement for every molecule\n",
    "im = tp.imsd(t1, 0.254, 0.2, max_lagtime=6)  # microns per pixel = 0.254, frames per second = 0.2, D calculated from first 6 pts\n",
    "slope = np.linalg.lstsq(im.index[:, np.newaxis], im)[0][0]\n",
    "\n",
    "#plot MSDs\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(im.index, im, 'k-', alpha=0.3)  # black lines, semitransparent\n",
    "ax.set(ylabel=r'$\\langle \\Delta r^2 \\rangle$ [um$^2$]',\n",
    "       xlabel='lag time $t$')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "#ax.set(xlim=(0, 16), ylim=(0, 20))\n",
    "\n",
    "#calculates D for every molecule\n",
    "D = (slope/4)*(10**6)\n",
    "#print(D)\n",
    "D.sort() \n",
    "print(D)\n",
    "med = np.median(D)#calculates the median D\n",
    "print(r'The median diffusion coefficient is {0:.3f} nmÂ²/s'.format(med))\n",
    "\n",
    "#saves Diffusion coefficients in a csv file\n",
    "np.savetxt(name +'D.csv', D, delimiter=',', comments=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
